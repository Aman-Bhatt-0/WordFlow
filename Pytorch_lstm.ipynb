{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkt7+jS4o2TNBPO8T1yNsv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aman-Bhatt-0/WordFlow/blob/main/Pytorch_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NfcpnluzLzo",
        "outputId": "ed45c728-bc80-430a-9810-5e81ee22aaad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "ae7dunqczT8Q"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables computers to learn patterns from data.\n",
        "ML models improve automatically through experience and data exposure.\n",
        "The field of ML is divided into supervised, unsupervised, and reinforcement learning.\n",
        "Supervised Learning uses labeled data for training.\n",
        "Unsupervised Learning works with unlabeled data to find patterns.\n",
        "Reinforcement Learning trains an agent through rewards and penalties.\n",
        "Common ML applications include recommendation systems, fraud detection, and self-driving cars.\n",
        "ML is heavily used in healthcare, finance, e-commerce, and robotics.\n",
        "The accuracy of an ML model depends on the quality and quantity of data.\n",
        "Garbage in, garbage out—poor-quality data leads to poor models.\n",
        "Supervised learning includes regression and classification problems.\n",
        "Regression models predict continuous values (e.g., predicting house prices).\n",
        "Classification models predict categorical labels (e.g., spam detection).\n",
        "Unsupervised learning groups data into clusters (e.g., customer segmentation).\n",
        "Clustering algorithms include K-Means and DBSCAN.\n",
        "Dimensionality reduction techniques like PCA help visualize high-dimensional data.\n",
        "Reinforcement learning is inspired by behavioral psychology.\n",
        "Deep Q-Networks (DQN) are popular in reinforcement learning.\n",
        "Neural networks are inspired by the human brain.\n",
        "Deep learning is a subset of ML that uses multi-layered neural networks.\n",
        "Linear Regression is used for predicting continuous values.\n",
        "Logistic Regression is a classification algorithm.\n",
        "Decision Trees split data based on conditions to make predictions.\n",
        "Random Forest is an ensemble method using multiple decision trees.\n",
        "Support Vector Machines (SVM) are effective for high-dimensional data.\n",
        "K-Nearest Neighbors (KNN) is a simple yet powerful classification algorithm.\n",
        "Naïve Bayes is based on Bayes' theorem and works well for text classification.\n",
        "Gradient Boosting algorithms like XGBoost are widely used in competitions.\n",
        "Neural Networks use interconnected layers to process data.\n",
        "Long Short-Term Memory (LSTM) networks handle sequential data.\n",
        "Data collection is the first step in an ML project.\n",
        "Data preprocessing includes cleaning and transforming data.\n",
        "Feature engineering improves model performance.\n",
        "Feature selection removes irrelevant features to avoid overfitting.\n",
        "Model selection involves choosing the best algorithm for a given problem.\n",
        "Model training requires feeding data into the algorithm.\n",
        "Hyperparameter tuning optimizes the model's performance.\n",
        "Cross-validation ensures that models generalize well.\n",
        "Overfitting happens when a model learns noise instead of patterns.\n",
        "Underfitting occurs when a model is too simple to capture trends.\n",
        "Spam filters use ML to classify emails as spam or not spam.\n",
        "Netflix and YouTube recommend content using ML models.\n",
        "Google Search uses ML for ranking pages.\n",
        "Stock market predictions use ML to analyze financial trends.\n",
        "Autonomous vehicles rely on ML for decision-making.\n",
        "Medical diagnosis benefits from ML-powered image analysis.\n",
        "Fraud detection in banks relies on anomaly detection techniques.\n",
        "Chatbots and virtual assistants use ML for natural language understanding.\n",
        "E-commerce platforms use ML for product recommendations.\n",
        "Voice recognition in Siri and Alexa is powered by ML models.\n",
        "Scikit-Learn is a Python library for ML.\n",
        "TensorFlow is an open-source ML framework by Google.\n",
        "PyTorch is widely used for deep learning.\n",
        "Keras simplifies neural network implementation.\n",
        "XGBoost is the go-to library for gradient boosting.\n",
        "Pandas helps with data manipulation.\n",
        "Matplotlib and Seaborn are used for data visualization.\n",
        "NLTK and spaCy are useful for NLP tasks.\n",
        "OpenCV is used for computer vision tasks.\n",
        "Hugging Face Transformers provide state-of-the-art NLP models.\n",
        "Data scarcity can limit ML performance.\n",
        "Bias in training data leads to unfair predictions.\n",
        "High computational power is needed for deep learning models.\n",
        "Interpretable AI is crucial for trustworthy ML.\n",
        "Adversarial attacks can fool ML models.\n",
        "Scalability issues arise when working with big data.\n",
        "Ethical concerns about AI-generated decisions are growing.\n",
        "Data privacy is a major challenge in ML applications.\n",
        "Generalization ensures that ML models perform well on unseen data.\n",
        "Model drift happens when real-world data changes over time.\n",
        "AutoML automates the process of ML model selection and tuning.\n",
        "Quantum Machine Learning is an emerging field.\n",
        "Federated Learning allows ML models to be trained on decentralized data.\n",
        "Explainable AI (XAI) makes ML models more transparent.\n",
        "AI ethics is becoming an important research area.\n",
        "ML in drug discovery speeds up medical research.\n",
        "TinyML enables ML on edge devices.\n",
        "ML in cybersecurity improves threat detection.\n",
        "Self-supervised learning is a new frontier in ML.\n",
        "Human-AI collaboration is the future of intelligent systems.\n",
        "Deep Learning became mainstream after 2012.\n",
        "Google’s AlphaGo defeated human champions in Go.\n",
        "Facebook’s AI once created its own language before being shut down.\n",
        "Reinforcement learning helped train robotic dogs.\n",
        "ChatGPT is built using a large-scale Transformer model.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "fLwm0Y_MzVuh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMU_RwfbzXt4",
        "outputId": "6b3824cc-0440-4af8-ee5e-dc77614ef0f8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "t28bgAcszaHl"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocab\n",
        "vocab = {'<unk>':0}\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G30GxEjgzcfY",
        "outputId": "5f47b6c7-4b13-4c0f-b155-9120af27351b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'machine': 1,\n",
              " 'learning': 2,\n",
              " '(': 3,\n",
              " 'ml': 4,\n",
              " ')': 5,\n",
              " 'is': 6,\n",
              " 'a': 7,\n",
              " 'subset': 8,\n",
              " 'of': 9,\n",
              " 'artificial': 10,\n",
              " 'intelligence': 11,\n",
              " 'ai': 12,\n",
              " 'that': 13,\n",
              " 'enables': 14,\n",
              " 'computers': 15,\n",
              " 'to': 16,\n",
              " 'learn': 17,\n",
              " 'patterns': 18,\n",
              " 'from': 19,\n",
              " 'data': 20,\n",
              " '.': 21,\n",
              " 'models': 22,\n",
              " 'improve': 23,\n",
              " 'automatically': 24,\n",
              " 'through': 25,\n",
              " 'experience': 26,\n",
              " 'and': 27,\n",
              " 'exposure': 28,\n",
              " 'the': 29,\n",
              " 'field': 30,\n",
              " 'divided': 31,\n",
              " 'into': 32,\n",
              " 'supervised': 33,\n",
              " ',': 34,\n",
              " 'unsupervised': 35,\n",
              " 'reinforcement': 36,\n",
              " 'uses': 37,\n",
              " 'labeled': 38,\n",
              " 'for': 39,\n",
              " 'training': 40,\n",
              " 'works': 41,\n",
              " 'with': 42,\n",
              " 'unlabeled': 43,\n",
              " 'find': 44,\n",
              " 'trains': 45,\n",
              " 'an': 46,\n",
              " 'agent': 47,\n",
              " 'rewards': 48,\n",
              " 'penalties': 49,\n",
              " 'common': 50,\n",
              " 'applications': 51,\n",
              " 'include': 52,\n",
              " 'recommendation': 53,\n",
              " 'systems': 54,\n",
              " 'fraud': 55,\n",
              " 'detection': 56,\n",
              " 'self-driving': 57,\n",
              " 'cars': 58,\n",
              " 'heavily': 59,\n",
              " 'used': 60,\n",
              " 'in': 61,\n",
              " 'healthcare': 62,\n",
              " 'finance': 63,\n",
              " 'e-commerce': 64,\n",
              " 'robotics': 65,\n",
              " 'accuracy': 66,\n",
              " 'model': 67,\n",
              " 'depends': 68,\n",
              " 'on': 69,\n",
              " 'quality': 70,\n",
              " 'quantity': 71,\n",
              " 'garbage': 72,\n",
              " 'out—poor-quality': 73,\n",
              " 'leads': 74,\n",
              " 'poor': 75,\n",
              " 'includes': 76,\n",
              " 'regression': 77,\n",
              " 'classification': 78,\n",
              " 'problems': 79,\n",
              " 'predict': 80,\n",
              " 'continuous': 81,\n",
              " 'values': 82,\n",
              " 'e.g.': 83,\n",
              " 'predicting': 84,\n",
              " 'house': 85,\n",
              " 'prices': 86,\n",
              " 'categorical': 87,\n",
              " 'labels': 88,\n",
              " 'spam': 89,\n",
              " 'groups': 90,\n",
              " 'clusters': 91,\n",
              " 'customer': 92,\n",
              " 'segmentation': 93,\n",
              " 'clustering': 94,\n",
              " 'algorithms': 95,\n",
              " 'k-means': 96,\n",
              " 'dbscan': 97,\n",
              " 'dimensionality': 98,\n",
              " 'reduction': 99,\n",
              " 'techniques': 100,\n",
              " 'like': 101,\n",
              " 'pca': 102,\n",
              " 'help': 103,\n",
              " 'visualize': 104,\n",
              " 'high-dimensional': 105,\n",
              " 'inspired': 106,\n",
              " 'by': 107,\n",
              " 'behavioral': 108,\n",
              " 'psychology': 109,\n",
              " 'deep': 110,\n",
              " 'q-networks': 111,\n",
              " 'dqn': 112,\n",
              " 'are': 113,\n",
              " 'popular': 114,\n",
              " 'neural': 115,\n",
              " 'networks': 116,\n",
              " 'human': 117,\n",
              " 'brain': 118,\n",
              " 'multi-layered': 119,\n",
              " 'linear': 120,\n",
              " 'logistic': 121,\n",
              " 'algorithm': 122,\n",
              " 'decision': 123,\n",
              " 'trees': 124,\n",
              " 'split': 125,\n",
              " 'based': 126,\n",
              " 'conditions': 127,\n",
              " 'make': 128,\n",
              " 'predictions': 129,\n",
              " 'random': 130,\n",
              " 'forest': 131,\n",
              " 'ensemble': 132,\n",
              " 'method': 133,\n",
              " 'using': 134,\n",
              " 'multiple': 135,\n",
              " 'support': 136,\n",
              " 'vector': 137,\n",
              " 'machines': 138,\n",
              " 'svm': 139,\n",
              " 'effective': 140,\n",
              " 'k-nearest': 141,\n",
              " 'neighbors': 142,\n",
              " 'knn': 143,\n",
              " 'simple': 144,\n",
              " 'yet': 145,\n",
              " 'powerful': 146,\n",
              " 'naïve': 147,\n",
              " 'bayes': 148,\n",
              " \"'\": 149,\n",
              " 'theorem': 150,\n",
              " 'well': 151,\n",
              " 'text': 152,\n",
              " 'gradient': 153,\n",
              " 'boosting': 154,\n",
              " 'xgboost': 155,\n",
              " 'widely': 156,\n",
              " 'competitions': 157,\n",
              " 'use': 158,\n",
              " 'interconnected': 159,\n",
              " 'layers': 160,\n",
              " 'process': 161,\n",
              " 'long': 162,\n",
              " 'short-term': 163,\n",
              " 'memory': 164,\n",
              " 'lstm': 165,\n",
              " 'handle': 166,\n",
              " 'sequential': 167,\n",
              " 'collection': 168,\n",
              " 'first': 169,\n",
              " 'step': 170,\n",
              " 'project': 171,\n",
              " 'preprocessing': 172,\n",
              " 'cleaning': 173,\n",
              " 'transforming': 174,\n",
              " 'feature': 175,\n",
              " 'engineering': 176,\n",
              " 'improves': 177,\n",
              " 'performance': 178,\n",
              " 'selection': 179,\n",
              " 'removes': 180,\n",
              " 'irrelevant': 181,\n",
              " 'features': 182,\n",
              " 'avoid': 183,\n",
              " 'overfitting': 184,\n",
              " 'involves': 185,\n",
              " 'choosing': 186,\n",
              " 'best': 187,\n",
              " 'given': 188,\n",
              " 'problem': 189,\n",
              " 'requires': 190,\n",
              " 'feeding': 191,\n",
              " 'hyperparameter': 192,\n",
              " 'tuning': 193,\n",
              " 'optimizes': 194,\n",
              " \"'s\": 195,\n",
              " 'cross-validation': 196,\n",
              " 'ensures': 197,\n",
              " 'generalize': 198,\n",
              " 'happens': 199,\n",
              " 'when': 200,\n",
              " 'learns': 201,\n",
              " 'noise': 202,\n",
              " 'instead': 203,\n",
              " 'underfitting': 204,\n",
              " 'occurs': 205,\n",
              " 'too': 206,\n",
              " 'capture': 207,\n",
              " 'trends': 208,\n",
              " 'filters': 209,\n",
              " 'classify': 210,\n",
              " 'emails': 211,\n",
              " 'as': 212,\n",
              " 'or': 213,\n",
              " 'not': 214,\n",
              " 'netflix': 215,\n",
              " 'youtube': 216,\n",
              " 'recommend': 217,\n",
              " 'content': 218,\n",
              " 'google': 219,\n",
              " 'search': 220,\n",
              " 'ranking': 221,\n",
              " 'pages': 222,\n",
              " 'stock': 223,\n",
              " 'market': 224,\n",
              " 'analyze': 225,\n",
              " 'financial': 226,\n",
              " 'autonomous': 227,\n",
              " 'vehicles': 228,\n",
              " 'rely': 229,\n",
              " 'decision-making': 230,\n",
              " 'medical': 231,\n",
              " 'diagnosis': 232,\n",
              " 'benefits': 233,\n",
              " 'ml-powered': 234,\n",
              " 'image': 235,\n",
              " 'analysis': 236,\n",
              " 'banks': 237,\n",
              " 'relies': 238,\n",
              " 'anomaly': 239,\n",
              " 'chatbots': 240,\n",
              " 'virtual': 241,\n",
              " 'assistants': 242,\n",
              " 'natural': 243,\n",
              " 'language': 244,\n",
              " 'understanding': 245,\n",
              " 'platforms': 246,\n",
              " 'product': 247,\n",
              " 'recommendations': 248,\n",
              " 'voice': 249,\n",
              " 'recognition': 250,\n",
              " 'siri': 251,\n",
              " 'alexa': 252,\n",
              " 'powered': 253,\n",
              " 'scikit-learn': 254,\n",
              " 'python': 255,\n",
              " 'library': 256,\n",
              " 'tensorflow': 257,\n",
              " 'open-source': 258,\n",
              " 'framework': 259,\n",
              " 'pytorch': 260,\n",
              " 'keras': 261,\n",
              " 'simplifies': 262,\n",
              " 'network': 263,\n",
              " 'implementation': 264,\n",
              " 'go-to': 265,\n",
              " 'pandas': 266,\n",
              " 'helps': 267,\n",
              " 'manipulation': 268,\n",
              " 'matplotlib': 269,\n",
              " 'seaborn': 270,\n",
              " 'visualization': 271,\n",
              " 'nltk': 272,\n",
              " 'spacy': 273,\n",
              " 'useful': 274,\n",
              " 'nlp': 275,\n",
              " 'tasks': 276,\n",
              " 'opencv': 277,\n",
              " 'computer': 278,\n",
              " 'vision': 279,\n",
              " 'hugging': 280,\n",
              " 'face': 281,\n",
              " 'transformers': 282,\n",
              " 'provide': 283,\n",
              " 'state-of-the-art': 284,\n",
              " 'scarcity': 285,\n",
              " 'can': 286,\n",
              " 'limit': 287,\n",
              " 'bias': 288,\n",
              " 'unfair': 289,\n",
              " 'high': 290,\n",
              " 'computational': 291,\n",
              " 'power': 292,\n",
              " 'needed': 293,\n",
              " 'interpretable': 294,\n",
              " 'crucial': 295,\n",
              " 'trustworthy': 296,\n",
              " 'adversarial': 297,\n",
              " 'attacks': 298,\n",
              " 'fool': 299,\n",
              " 'scalability': 300,\n",
              " 'issues': 301,\n",
              " 'arise': 302,\n",
              " 'working': 303,\n",
              " 'big': 304,\n",
              " 'ethical': 305,\n",
              " 'concerns': 306,\n",
              " 'about': 307,\n",
              " 'ai-generated': 308,\n",
              " 'decisions': 309,\n",
              " 'growing': 310,\n",
              " 'privacy': 311,\n",
              " 'major': 312,\n",
              " 'challenge': 313,\n",
              " 'generalization': 314,\n",
              " 'perform': 315,\n",
              " 'unseen': 316,\n",
              " 'drift': 317,\n",
              " 'real-world': 318,\n",
              " 'changes': 319,\n",
              " 'over': 320,\n",
              " 'time': 321,\n",
              " 'automl': 322,\n",
              " 'automates': 323,\n",
              " 'quantum': 324,\n",
              " 'emerging': 325,\n",
              " 'federated': 326,\n",
              " 'allows': 327,\n",
              " 'be': 328,\n",
              " 'trained': 329,\n",
              " 'decentralized': 330,\n",
              " 'explainable': 331,\n",
              " 'xai': 332,\n",
              " 'makes': 333,\n",
              " 'more': 334,\n",
              " 'transparent': 335,\n",
              " 'ethics': 336,\n",
              " 'becoming': 337,\n",
              " 'important': 338,\n",
              " 'research': 339,\n",
              " 'area': 340,\n",
              " 'drug': 341,\n",
              " 'discovery': 342,\n",
              " 'speeds': 343,\n",
              " 'up': 344,\n",
              " 'tinyml': 345,\n",
              " 'edge': 346,\n",
              " 'devices': 347,\n",
              " 'cybersecurity': 348,\n",
              " 'threat': 349,\n",
              " 'self-supervised': 350,\n",
              " 'new': 351,\n",
              " 'frontier': 352,\n",
              " 'human-ai': 353,\n",
              " 'collaboration': 354,\n",
              " 'future': 355,\n",
              " 'intelligent': 356,\n",
              " 'became': 357,\n",
              " 'mainstream': 358,\n",
              " 'after': 359,\n",
              " '2012.': 360,\n",
              " '’': 361,\n",
              " 's': 362,\n",
              " 'alphago': 363,\n",
              " 'defeated': 364,\n",
              " 'champions': 365,\n",
              " 'go': 366,\n",
              " 'facebook': 367,\n",
              " 'once': 368,\n",
              " 'created': 369,\n",
              " 'its': 370,\n",
              " 'own': 371,\n",
              " 'before': 372,\n",
              " 'being': 373,\n",
              " 'shut': 374,\n",
              " 'down': 375,\n",
              " 'helped': 376,\n",
              " 'train': 377,\n",
              " 'robotic': 378,\n",
              " 'dogs': 379,\n",
              " 'chatgpt': 380,\n",
              " 'built': 381,\n",
              " 'large-scale': 382,\n",
              " 'transformer': 383}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOOEZ94P0dQ1",
        "outputId": "00644659-ceba-4746-837a-2dbc68934ff3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = document.split('\\n')"
      ],
      "metadata": {
        "id": "RefNavJe1Cva"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "\n",
        "  numerical_sentence = []\n",
        "\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "\n",
        "  return numerical_sentence\n"
      ],
      "metadata": {
        "id": "x52A3E1K1zjn"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numerical_sentences = []\n",
        "\n",
        "for sentence in input_sentences:\n",
        "  input_numerical_sentences.append(text_to_indices(word_tokenize(sentence.lower()), vocab))\n"
      ],
      "metadata": {
        "id": "eu66Zo3e1Wh9"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_numerical_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxJesAQC1et3",
        "outputId": "4cf5801b-4c16-4e3f-8e3d-7c43694a5113"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence = []\n",
        "for sentence in input_numerical_sentences:\n",
        "\n",
        "  for i in range(1, len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])"
      ],
      "metadata": {
        "id": "80rIx4aq6ele"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_aGJ0fy7swk",
        "outputId": "9a2a2d10-d215-4ea2-ea9b-0e3a0dc64988"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "756"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrFzZ4DD8Anu",
        "outputId": "e4b65acd-0e0a-4ea4-b3c8-dc0a8b02873b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "\n",
        "for sequence in training_sequence:\n",
        "  len_list.append(len(sequence))\n",
        "\n",
        "max(len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2Z_fiVZ8GRo",
        "outputId": "c749df46-9557-4828-b2e3-ee00bdd60eec"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bIcIRd088EN",
        "outputId": "363b4907-7f6f-42cc-8ca2-cfbb1347a3e7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = []\n",
        "for sequence in training_sequence:\n",
        "\n",
        "  padded_training_sequence.append([0]*(max(len_list) - len(sequence)) + sequence)"
      ],
      "metadata": {
        "id": "dtPg5uRN9Cc7"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_training_sequence[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqZssF989X-4",
        "outputId": "d2b7c015-1b30-4499-94ff-a93d50d95da6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)"
      ],
      "metadata": {
        "id": "0_wVpepb9iE4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogKvdXa79yxV",
        "outputId": "820118ec-60e8-41b8-c5d4-8b26d2226dd2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        [  0,   0,   0,  ...,   2,   3,   4],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ...,   7, 382, 383],\n",
              "        [  0,   0,   0,  ..., 382, 383,  67],\n",
              "        [  0,   0,   0,  ..., 383,  67,  21]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_training_sequence[:, :-1]\n",
        "y = padded_training_sequence[:,-1]"
      ],
      "metadata": {
        "id": "Tz8fwCok90m0"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ed_PLHJ-Dgv",
        "outputId": "19425c54-b39f-4457-b904-488d1b2067b2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   0,   1],\n",
              "        [  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ..., 134,   7, 382],\n",
              "        [  0,   0,   0,  ...,   7, 382, 383],\n",
              "        [  0,   0,   0,  ..., 382, 383,  67]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eReVrcX9-EUU",
        "outputId": "03e8a66f-7a76-48fa-975f-0f5c8682ae58"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   3,   4,   5,   6,   7,   8,   9,  10,  11,   3,  12,   5,  13,\n",
              "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
              "         20,  28,  21,  30,   9,   4,   6,  31,  32,  33,  34,  35,  34,  27,\n",
              "         36,   2,  21,   2,  37,  38,  20,  39,  40,  21,   2,  41,  42,  43,\n",
              "         20,  16,  44,  18,  21,   2,  45,  46,  47,  25,  48,  27,  49,  21,\n",
              "          4,  51,  52,  53,  54,  34,  55,  56,  34,  27,  57,  58,  21,   6,\n",
              "         59,  60,  61,  62,  34,  63,  34,  64,  34,  27,  65,  21,  66,   9,\n",
              "         46,   4,  67,  68,  69,  29,  70,  27,  71,   9,  20,  21,  61,  34,\n",
              "         72,  73,  20,  74,  16,  75,  22,  21,   2,  76,  77,  27,  78,  79,\n",
              "         21,  22,  80,  81,  82,   3,  83,  34,  84,  85,  86,   5,  21,  22,\n",
              "         80,  87,  88,   3,  83,  34,  89,  56,   5,  21,   2,  90,  20,  32,\n",
              "         91,   3,  83,  34,  92,  93,   5,  21,  95,  52,  96,  27,  97,  21,\n",
              "         99, 100, 101, 102, 103, 104, 105,  20,  21,   2,   6, 106, 107, 108,\n",
              "        109,  21, 111,   3, 112,   5, 113, 114,  61,  36,   2,  21, 116, 113,\n",
              "        106, 107,  29, 117, 118,  21,   2,   6,   7,   8,   9,   4,  13,  37,\n",
              "        119, 115, 116,  21,  77,   6,  60,  39,  84,  81,  82,  21,  77,   6,\n",
              "          7,  78, 122,  21, 124, 125,  20, 126,  69, 127,  16, 128, 129,  21,\n",
              "        131,   6,  46, 132, 133, 134, 135, 123, 124,  21, 137, 138,   3, 139,\n",
              "          5, 113, 140,  39, 105,  20,  21, 142,   3, 143,   5,   6,   7, 144,\n",
              "        145, 146,  78, 122,  21, 148,   6, 126,  69, 148, 149, 150,  27,  41,\n",
              "        151,  39, 152,  78,  21, 154,  95, 101, 155, 113, 156,  60,  61, 157,\n",
              "         21, 116, 158, 159, 160,  16, 161,  20,  21, 163, 164,   3, 165,   5,\n",
              "        116, 166, 167,  20,  21, 168,   6,  29, 169, 170,  61,  46,   4, 171,\n",
              "         21, 172,  76, 173,  27, 174,  20,  21, 176, 177,  67, 178,  21, 179,\n",
              "        180, 181, 182,  16, 183, 184,  21, 179, 185, 186,  29, 187, 122,  39,\n",
              "          7, 188, 189,  21,  40, 190, 191,  20,  32,  29, 122,  21, 193, 194,\n",
              "         29,  67, 195, 178,  21, 197,  13,  22, 198, 151,  21, 199, 200,   7,\n",
              "         67, 201, 202, 203,   9,  18,  21, 205, 200,   7,  67,   6, 206, 144,\n",
              "         16, 207, 208,  21, 209, 158,   4,  16, 210, 211, 212,  89, 213, 214,\n",
              "         89,  21,  27, 216, 217, 218, 134,   4,  22,  21, 220,  37,   4,  39,\n",
              "        221, 222,  21, 224, 129, 158,   4,  16, 225, 226, 208,  21, 228, 229,\n",
              "         69,   4,  39, 230,  21, 232, 233,  19, 234, 235, 236,  21,  56,  61,\n",
              "        237, 238,  69, 239,  56, 100,  21,  27, 241, 242, 158,   4,  39, 243,\n",
              "        244, 245,  21, 246, 158,   4,  39, 247, 248,  21, 250,  61, 251,  27,\n",
              "        252,   6, 253, 107,   4,  22,  21,   6,   7, 255, 256,  39,   4,  21,\n",
              "          6,  46, 258,   4, 259, 107, 219,  21,   6, 156,  60,  39, 110,   2,\n",
              "         21, 262, 115, 263, 264,  21,   6,  29, 265, 256,  39, 153, 154,  21,\n",
              "        267,  42,  20, 268,  21,  27, 270, 113,  60,  39,  20, 271,  21,  27,\n",
              "        273, 113, 274,  39, 275, 276,  21,   6,  60,  39, 278, 279, 276,  21,\n",
              "        281, 282, 283, 284, 275,  22,  21, 285, 286, 287,   4, 178,  21,  61,\n",
              "         40,  20,  74,  16, 289, 129,  21, 291, 292,   6, 293,  39, 110,   2,\n",
              "         22,  21,  12,   6, 295,  39, 296,   4,  21, 298, 286, 299,   4,  22,\n",
              "         21, 301, 302, 200, 303,  42, 304,  20,  21, 306, 307, 308, 309, 113,\n",
              "        310,  21, 311,   6,   7, 312, 313,  61,   4,  51,  21, 197,  13,   4,\n",
              "         22, 315, 151,  69, 316,  20,  21, 317, 199, 200, 318,  20, 319, 320,\n",
              "        321,  21, 323,  29, 161,   9,   4,  67, 179,  27, 193,  21,   1,   2,\n",
              "          6,  46, 325,  30,  21,   2, 327,   4,  22,  16, 328, 329,  69, 330,\n",
              "         20,  21,  12,   3, 332,   5, 333,   4,  22, 334, 335,  21, 336,   6,\n",
              "        337,  46, 338, 339, 340,  21,  61, 341, 342, 343, 344, 231, 339,  21,\n",
              "         14,   4,  69, 346, 347,  21,  61, 348, 177, 349,  56,  21,   2,   6,\n",
              "          7, 351, 352,  61,   4,  21, 354,   6,  29, 355,   9, 356,  54,  21,\n",
              "          2, 357, 358, 359,   0,  21, 361, 362, 363, 364, 117, 365,  61, 366,\n",
              "         21, 361, 362,  12, 368, 369, 370, 371, 244, 372, 373, 374, 375,  21,\n",
              "          2, 376, 377, 378, 379,  21,   6, 381, 134,   7, 382, 383,  67,  21])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "fR059hVd-IAf"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X,y)"
      ],
      "metadata": {
        "id": "KLX0clQM_j9r"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYHaeSuI_nJX",
        "outputId": "643113f2-c8dc-4996-e97c-5bb27b12d012"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "756"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "7ZUeD3l6_oZ3"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "0TEukXmWDEn8"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(len(vocab))"
      ],
      "metadata": {
        "id": "YcQEVc9aVgr5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Lvm7W6L1X6P1"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXwq43NRYD3q",
        "outputId": "a60545e3-f65b-4bd8-f4ec-9d7ec75dac2d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(384, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=384, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1faORN1VYFdu"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  for batch_x, batch_y in dataloader:\n",
        "\n",
        "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(batch_x)\n",
        "\n",
        "    loss = criterion(output, batch_y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch + 1}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRLc1cbrYVVV",
        "outputId": "20b05093-fcf9-426b-d9f4-f388426ba27a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 141.1462\n",
            "Epoch: 2, Loss: 124.8889\n",
            "Epoch: 3, Loss: 114.3605\n",
            "Epoch: 4, Loss: 107.9957\n",
            "Epoch: 5, Loss: 101.3025\n",
            "Epoch: 6, Loss: 95.1222\n",
            "Epoch: 7, Loss: 88.5378\n",
            "Epoch: 8, Loss: 81.4073\n",
            "Epoch: 9, Loss: 75.0420\n",
            "Epoch: 10, Loss: 68.7202\n",
            "Epoch: 11, Loss: 62.3594\n",
            "Epoch: 12, Loss: 56.3505\n",
            "Epoch: 13, Loss: 50.8002\n",
            "Epoch: 14, Loss: 45.5169\n",
            "Epoch: 15, Loss: 40.6069\n",
            "Epoch: 16, Loss: 35.9160\n",
            "Epoch: 17, Loss: 31.6570\n",
            "Epoch: 18, Loss: 27.7776\n",
            "Epoch: 19, Loss: 24.7134\n",
            "Epoch: 20, Loss: 21.8802\n",
            "Epoch: 21, Loss: 19.2002\n",
            "Epoch: 22, Loss: 16.9233\n",
            "Epoch: 23, Loss: 15.0158\n",
            "Epoch: 24, Loss: 13.3962\n",
            "Epoch: 25, Loss: 12.0503\n",
            "Epoch: 26, Loss: 10.8191\n",
            "Epoch: 27, Loss: 9.6974\n",
            "Epoch: 28, Loss: 8.8294\n",
            "Epoch: 29, Loss: 8.0376\n",
            "Epoch: 30, Loss: 7.4214\n",
            "Epoch: 31, Loss: 6.8726\n",
            "Epoch: 32, Loss: 6.3178\n",
            "Epoch: 33, Loss: 5.8977\n",
            "Epoch: 34, Loss: 5.5155\n",
            "Epoch: 35, Loss: 5.1469\n",
            "Epoch: 36, Loss: 4.8311\n",
            "Epoch: 37, Loss: 4.5661\n",
            "Epoch: 38, Loss: 4.3282\n",
            "Epoch: 39, Loss: 4.1913\n",
            "Epoch: 40, Loss: 3.9897\n",
            "Epoch: 41, Loss: 3.7547\n",
            "Epoch: 42, Loss: 3.6006\n",
            "Epoch: 43, Loss: 3.3895\n",
            "Epoch: 44, Loss: 3.2837\n",
            "Epoch: 45, Loss: 3.1762\n",
            "Epoch: 46, Loss: 3.0806\n",
            "Epoch: 47, Loss: 2.9730\n",
            "Epoch: 48, Loss: 2.9068\n",
            "Epoch: 49, Loss: 2.7410\n",
            "Epoch: 50, Loss: 2.7053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model, vocab, text):\n",
        "\n",
        "  # tokenize\n",
        "  tokenized_text = word_tokenize(text.lower())\n",
        "\n",
        "  # text -> numerical indices\n",
        "  numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "\n",
        "  # padding\n",
        "  padded_text = torch.tensor([0] * (61 - len(numerical_text)) + numerical_text, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "  # Move padded_text to the same device as the model\n",
        "  padded_text = padded_text.to(device)\n",
        "\n",
        "  # send to model\n",
        "  output = model(padded_text)\n",
        "\n",
        "  # predicted index\n",
        "  value, index = torch.max(output, dim=1)\n",
        "\n",
        "  # merge with text\n",
        "  return text + \" \" + list(vocab.keys())[index]"
      ],
      "metadata": {
        "id": "O9f6DkX-ZM-r"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model, vocab, \"divided into supervised,\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VsRgcJysbGCg",
        "outputId": "55da7ef5-399f-4705-fcda-2f6ac6a7ff28"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'divided into supervised, and'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "num_tokens = 10\n",
        "input_text = \"Machine Learning (ML) is a subset of Artificial Intelligence (AI)\"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "  output_text = prediction(model, vocab, input_text)\n",
        "  print(output_text)\n",
        "  input_text = output_text\n",
        "  time.sleep(0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_JPACfEbNPo",
        "outputId": "28882a75-0392-4f61-976e-11a6c70d6425"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that\n",
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables\n",
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables computers\n",
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables computers to\n",
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables computers to learn\n",
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables computers to learn patterns\n",
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables computers to learn patterns from\n",
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables computers to learn patterns from data\n",
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables computers to learn patterns from data .\n",
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables computers to learn patterns from data . .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader1 = DataLoader(dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "JXsV4AnNXNnw"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to compute gradients\n",
        "        for batch_x, batch_y in dataloader1:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            # Get model predictions\n",
        "            outputs = model(batch_x)\n",
        "\n",
        "            # Get the predicted word indices\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "            # Compare with actual labels\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = calculate_accuracy(model, dataloader, device)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Py7o0rJJc5pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f0c09f9-8c60-42d7-9dfa-24aa578d0c65"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 97.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bQnBuShXG5i"
      },
      "execution_count": 77,
      "outputs": []
    }
  ]
}